{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finetuning MORPH on [ICF data](https://github.com/LLNL/macc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# install required packages to download from Hugging Face Hub\n",
        "%pip -q install huggingface_hub\n",
        "%pip install hf_xet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# install required packages to get notebook path\n",
        "%pip install ipynbname --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set-up directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set cwd to the directory \n",
        "import os\n",
        "from pathlib import Path\n",
        "import ipynbname\n",
        "\n",
        "HERE = Path(ipynbname.path()).resolve().parent\n",
        "ROOT = HERE.parents[1]\n",
        "os.chdir(HERE)\n",
        "print(\"Current directory: \", os.getcwd())\n",
        "os.chdir(ROOT)\n",
        "print(\"Root directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define important directories\n",
        "dataset_dir = os.path.join(ROOT, \"datasets\")\n",
        "data_dir = os.path.join(ROOT, \"data\")\n",
        "model_dir = os.path.join(ROOT, \"models\")\n",
        "results_dir = os.path.join(ROOT, \"experiments\", \"results\")\n",
        "print(\"Dataset directory:\", dataset_dir)\n",
        "print(\"Data directory:\", data_dir)\n",
        "print(\"Model directory:\", model_dir)\n",
        "print(\"Results directory:\", results_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load ICF dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXIjineSr8DD",
        "outputId": "7783fdb3-d05b-4a8d-87bb-706ab4acd0e7"
      },
      "outputs": [],
      "source": [
        "# Load ICF-JAG-10K dataset\n",
        "import os, numpy as np\n",
        "\n",
        "path_images = os.path.join(dataset_dir, \"icf-jag-10k\", \"jag10K_images.npy\")\n",
        "path_params = os.path.join(dataset_dir, \"icf-jag-10k\", \"jag10K_params.npy\")\n",
        "path_scalars = os.path.join(dataset_dir, \"icf-jag-10k\", \"jag10K_0_scalars.npy\")\n",
        "\n",
        "images = np.load(path_images, allow_pickle=False).astype(np.float32)\n",
        "params = np.load(path_params, allow_pickle=False).astype(np.float32)\n",
        "scalars = np.load(path_scalars, allow_pickle=False).astype(np.float32)\n",
        "\n",
        "print(\"images.shape:\", images.shape)\n",
        "print(\"params.shape:\", params.shape)\n",
        "print(\"scalars.shape:\", scalars.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# some stats\n",
        "min_images, max_images = images.min(), images.max()\n",
        "mean_images, std_images = images.mean(), images.std()\n",
        "print(f\"images: min {min_images}, max {max_images}, mean {mean_images}, std {std_images}\")\n",
        "\n",
        "min_params, max_params = params.min(), params.max()\n",
        "mean_params, std_params = params.mean(), params.std()\n",
        "print(f\"params: min {min_params}, max {max_params}, mean {mean_params}, std {std_params}\")\n",
        "\n",
        "min_scalars, max_scalars = scalars.min(), scalars.max()\n",
        "mean_scalars, std_scalars = scalars.mean(), scalars.std()\n",
        "print(f\"scalars: min {min_scalars}, max {max_scalars}, mean {mean_scalars}, std {std_scalars}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Scalars and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(scalars[0:5,:],'-o')\n",
        "plt.title('Scalars')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(params[0:5,:],'-*')\n",
        "plt.title('Parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If not already reshaped:\n",
        "images_reshape = images.reshape(images.shape[0], 64, 64, 4).astype(np.float32)\n",
        "print(f\"Reshaped images: {images_reshape.shape}\")  # (N, 64, 64, 4)\n",
        "\n",
        "# pick 5 unique samples\n",
        "idxs = np.random.choice(images_reshape.shape[0], 5, replace=False)\n",
        "\n",
        "fig, axes = plt.subplots(len(idxs), 4, figsize=(8, 2*len(idxs)))\n",
        "\n",
        "# handle the case axes is 2D\n",
        "for r, idx in enumerate(idxs):\n",
        "    for c in range(4):\n",
        "        ax = axes[r, c]\n",
        "        ax.imshow(images_reshape[idx, :, :, c], cmap='plasma', origin='lower')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        if r == 0:\n",
        "            ax.set_title(f'Channel {c}')\n",
        "        if c == 0:\n",
        "            ax.set_ylabel(f'Sample {idx}')\n",
        "\n",
        "plt.suptitle('Five samples × four channels')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data Normalization\n",
        "- We perform Reverse Instance Normalization (ReVIN) [Paper](https://openreview.net/forum?id=cGDAkQo1C0p).\n",
        "- For every (Sample, Field), it calculates ($\\mu$,$\\sigma$)\n",
        "- After training, ($\\mu$,$\\sigma$) can be used for denormalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data in (N, T, D, H, W, C, F) format\n",
        "E_1 = images_reshape[:, :, :, 0]\n",
        "E_2 = images_reshape[:, :, :, 1]\n",
        "E_3 = images_reshape[:, :, :, 2]\n",
        "E_4 = images_reshape[:, :, :, 3]\n",
        "\n",
        "# Organize data into components\n",
        "E_12 = np.stack((E_1, E_2), axis=-1)[..., np.newaxis]  # (N, H, W, C, F) -> (N, 64, 64, 2, 1)\n",
        "E_34 = np.stack((E_3, E_4), axis=-1)[..., np.newaxis]  # (N, H, W, C, F) -> (N, 64, 64, 2, 1)\n",
        "E_13 = np.stack((E_1, E_3), axis=-1)[..., np.newaxis]  # (N, 64, 64, 2, 1)\n",
        "E_24 = np.stack((E_2, E_4), axis=-1)[..., np.newaxis]  # (N, 64, 64, 2, 1)\n",
        "\n",
        "# Organize data into fields and components\n",
        "# type - 1 where E12 and E34 are groups as fields \n",
        "data_1 = np.concatenate((E_12, E_34), axis=-1)  # (N, 64, 64, 2, 2)\n",
        "print(f\"Organized data shape (type-1): {data_1.shape}\")  # (N, 64, 64, 2, 2)\n",
        "\n",
        "# type - 2 where E13 and E24 are groups as fields\n",
        "data_2 = np.concatenate((E_13, E_24), axis=-1)  # (N, 64, 64, 2, 2)\n",
        "print(f\"Organized data shape (type-2): {data_2.shape}\")  # (N, 64, 64, 2, 2)\n",
        "\n",
        "data  = data_1  # choose one organization\n",
        "print(f\"Final data shape (N,H,W,C,F): {data.shape}\")  # (N, 64, 64, 2, 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bring data into (N, T, D, H, W, C, F) format\n",
        "data = data[:, np.newaxis, np.newaxis, :, :, :, :]  # (N, 1, 1, 64, 64, 2, 2)\n",
        "print(f\"Data shape (N, T, D, H, W, F, C): {data.shape}\")  # (N, 1, 1, 64, 64, 2, 2)\n",
        "\n",
        "# Reshape the data in UPTF-7 format\n",
        "data = data.transpose(0, 1, 6, 5, 2, 3, 4)  # (N, T, F, C, D, H, W)\n",
        "print(f\"Data shape (N, T, F, C, D, H, W): {data.shape}\")  # (N, 1, 2, 2, 1, 64, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Call normalization function\n",
        "from src.utils.normalization import RevIN\n",
        "rev_icf = RevIN(data_dir)\n",
        "\n",
        "# compute & normalize -> Needs data in UPTF-7 format\n",
        "rev_icf.compute_stats(data, prefix='stats_icf')\n",
        "dataset_icf_norm = rev_icf.normalize(data, prefix='stats_icf')\n",
        "print(\"Normalize dataset shape\", dataset_icf_norm.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check round‐trip via denormalize\n",
        "tol_2 = 1e-4\n",
        "recovered = rev_icf.denormalize(dataset_icf_norm, prefix='stats_icf')\n",
        "print(\"Denormalized dataset shape\", recovered.shape)\n",
        "\n",
        "max_error = 0.0\n",
        "for i in range(recovered.shape[0]):\n",
        "    maxerror_i = np.max(np.abs(recovered[i] - data[i]))  # saving some memory\n",
        "    max_error = max(maxerror_i, max_error)\n",
        "assert max_error < tol_2, \"Denormalization did not perfectly recover original!\"\n",
        "print(\"RevIN round-trip OK\")\n",
        "del recovered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the parameters\n",
        "import matplotlib.pyplot as plt\n",
        "colors = ['C0', 'C1', 'C2', 'C3', 'C4']\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(params.shape[1]):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.hist(params[:,i], bins=50, alpha=0.7, color = colors[i])\n",
        "    plt.title(f'Parameter {i+1}', fontsize=16)\n",
        "    plt.xlabel('Value', fontsize=16)\n",
        "    if i == 0:\n",
        "        plt.ylabel('Frequency', fontsize=16)\n",
        "    plt.legend([f'Parameter {i+1}'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize function\n",
        "def normalize_params(params):\n",
        "    for i in range(params.shape[1]):\n",
        "        mu_params = params[:,i].mean()\n",
        "        std_params = params[:,i].std()\n",
        "        print(f\"Param {i+1}: mean {mu_params}, std {std_params}\")\n",
        "        params[:,i] = (params[:,i] - mu_params) / std_params\n",
        "    return params\n",
        "\n",
        "# Denormalize function\n",
        "def denormalize_params(norm_params, mu_params, std_params):\n",
        "    return norm_params * std_params + mu_params\n",
        "\n",
        "# Normalize the parameters\n",
        "params_norm = normalize_params(params.copy())\n",
        "\n",
        "# Visualize the parameters\n",
        "import matplotlib.pyplot as plt\n",
        "colors = ['C0', 'C1', 'C2', 'C3', 'C4']\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(params_norm.shape[1]):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.hist(params_norm[:,i], bins=50, alpha=0.7, color = colors[i])\n",
        "    plt.title(f'Parameter {i+1}', fontsize=16)\n",
        "    plt.xlabel('Value', fontsize=16)\n",
        "    if i == 0:\n",
        "        plt.ylabel('Frequency', fontsize=16)\n",
        "    plt.legend([f'Parameter {i+1}'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# some stats\n",
        "for i in range(4):\n",
        "    min_images, max_images = dataset_icf_norm[..., i].min(), dataset_icf_norm[..., i].max()\n",
        "    print(f\"images: min {min_images}, max {max_images}\")\n",
        "\n",
        "for j in range(5):\n",
        "    min_params, max_params = params_norm[..., j].min(), params_norm[..., j].max()\n",
        "    print(f\"params: min {min_params}, max {max_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set Up Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data-scarce and compute-scarce scenarios\n",
        "dataset_size = 1000  # adjust as needed\n",
        "num_epochs = 10  # adjust as needed\n",
        "data_idx = np.random.choice(dataset_icf_norm.shape[0], dataset_size, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Device information\n",
        "import torch\n",
        "print(\"Number of CUDA devices\",torch.cuda.device_count())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# dataset class\n",
        "class DatasetforDataloader(Dataset):\n",
        "    def __init__(self,X,y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        # create a tuple\n",
        "        return self.X[i], self.y[i]\n",
        "    \n",
        "# Dataset of dataloader\n",
        "X = dataset_icf_norm[data_idx]\n",
        "y = params_norm[data_idx]\n",
        "full_dataset = DatasetforDataloader(X, y)\n",
        "\n",
        "# define the splits (80/10/10)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = int(0.1 * dataset_size)\n",
        "test_size = dataset_size - train_size - val_size\n",
        "\n",
        "# Split the dataset \n",
        "train, val, test = torch.utils.data.random_split(full_dataset,[train_size, val_size, test_size])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataloaders\n",
        "BATCH_SIZE = 8\n",
        "dataloader_train = DataLoader(train, batch_size = BATCH_SIZE, shuffle=True)\n",
        "dataloader_val = DataLoader(val, batch_size = BATCH_SIZE, shuffle=False)\n",
        "dataloader_test = DataLoader(test, batch_size = BATCH_SIZE, shuffle=False)\n",
        "print(f\"Number of training samples: {len(dataloader_train)}\")\n",
        "print(f\"Number of validation samples: {len(dataloader_val)}\")\n",
        "print(f\"Number of test samples: {len(dataloader_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Load MORPH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instantiate the foundational model\n",
        "from src.utils.vit_conv_xatt_axialatt2 import ViT3DRegression\n",
        "\n",
        "MORPH_MODELS = {\n",
        "    'Ti': [8, 256,  4,  4, 1024],\n",
        "    'S' : [8, 512,  8,  4, 2048],\n",
        "    'M' : [8, 768, 12,  8, 3072],\n",
        "    'L' : [8, 1024,16, 16, 4096]\n",
        "    }\n",
        "\n",
        "model_size = MORPH_MODELS['Ti']  # choose from 'Ti', 'S', 'M', 'L'\n",
        "filters, dim, depth, heads, mlp_dim = model_size\n",
        "heads_xa = 32\n",
        "dropout = 0.1\n",
        "emb_dropout = 0.1\n",
        "max_ar_order = 1\n",
        "patch_size = 8\n",
        "max_patches = 4096\n",
        "max_fields = 3\n",
        "max_components = 3\n",
        "\n",
        "# lora settings\n",
        "rank_lora_attn = 16\n",
        "rank_lora_mlp = 16\n",
        "lora_p = 0.05\n",
        "\n",
        "morph = ViT3DRegression(patch_size=patch_size, dim=dim, depth=depth,\n",
        "    heads=heads, heads_xa=heads_xa, mlp_dim=mlp_dim,\n",
        "    max_components=max_components, conv_filter=filters,\n",
        "    max_ar=max_ar_order,\n",
        "    max_patches=max_patches, max_fields=max_fields,\n",
        "    dropout=dropout, emb_dropout=emb_dropout,\n",
        "    lora_r_attn=rank_lora_attn,            # <— rank of A and B in the attention module\n",
        "    lora_r_mlp=rank_lora_mlp,              # <— rank of A and B in the MLP module\n",
        "    lora_alpha=None,                       # defaults to 2*rank inside LoRA\n",
        "    lora_p=lora_p                          # dropout on LoRA path\n",
        ").to(device)\n",
        "\n",
        "# print('Model architecture:', ft_model)\n",
        "num_params_model = sum(p.numel() for p in morph.parameters()) / 1e6\n",
        "print(f\"→ NUMBER OF PARAMETERS OF THE MODEL (in M): {num_params_model:.3g}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the foundational model weights\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# e.g., grab the \"Ti\" checkpoint (change filename as needed)\n",
        "weights_path = hf_hub_download(\n",
        "    repo_id=\"mahindrautela/MORPH\",\n",
        "    filename=\"morph-Ti-FM-max_ar1_ep225.pth\",\n",
        "    subfolder=\"models/FM\",\n",
        "    repo_type=\"model\",              # optional\n",
        "    resume_download=True,           # continue if interrupted\n",
        "    local_dir=\"weights/FM\",         # where to place it\n",
        "    local_dir_use_symlinks=False    # copy file instead of symlink\n",
        ")\n",
        "print(weights_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%% Load weights into the model\n",
        "import torch.nn as nn\n",
        "\n",
        "# ---- load the pretrained weights ----\n",
        "start_epoch = 0\n",
        "print(f\"→ Loading checkpoints from {weights_path}\")\n",
        "# --- Load pretrained checkpoint from foundational model ---\n",
        "ckpt = torch.load(weights_path, map_location=device, weights_only=True)\n",
        "state_dict = ckpt[\"model_state_dict\"]\n",
        "\n",
        "# pick the real model if wrapped   \n",
        "target = morph.module if isinstance(morph, nn.DataParallel) else morph \n",
        "\n",
        "if state_dict and next(iter(state_dict)).startswith(\"module.\"):\n",
        "    print(\"→ Stripping 'module.' from checkpoints\")\n",
        "    state_dict = {k.replace(\"module.\", \"\", 1): v for k, v in state_dict.items()}\n",
        "    \n",
        "# strict=False because ft_model has extra LoRA params (A/B) not in ckpt\n",
        "missing, unexpected = target.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "# sanity print\n",
        "print(\"Missing keys (expected: LoRA A/B etc.):\",\n",
        "        [k for k in missing if k.endswith((\".A\", \".B\")) or \".lora\" in k])\n",
        "print(\"Unexpected keys:\", unexpected)\n",
        "print(f\"→ Resumed from {weights_path}, starting at epoch {start_epoch}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Task-specific head (TSH) (Simple CNN1D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate number of patches and features per patch\n",
        "N_patches_W = X.shape[-2] // patch_size\n",
        "N_patches_H = X.shape[-1] // patch_size\n",
        "N_patches = N_patches_W * N_patches_H\n",
        "feat_per_patch = patch_size * patch_size * X.shape[2] * X.shape[3]\n",
        "print(f'Number of patches along W: {N_patches_W}, H: {N_patches_H}, Total Patches: {N_patches} \\n'\n",
        "      f'Feat_per_patch (patch_size * patch_size * C * F): {feat_per_patch}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Task-specific head model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TaskSpecificHead_CNN1D(nn.Module):\n",
        "    def __init__(self, n_patches=64, feat_dim=256, output_dim=5, dropout_p=0.1):\n",
        "        super().__init__()\n",
        "        self.n_patches = n_patches\n",
        "        self.feat_dim = feat_dim\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=feat_dim, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=128,      out_channels=64,  kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv1d(in_channels=64,       out_channels=32,  kernel_size=3, padding=1)\n",
        "\n",
        "        self.act  = nn.GELU()\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)  # 64->32->16->8\n",
        "        self.drop = nn.Dropout(dropout_p)\n",
        "\n",
        "        feat_len = n_patches // 8                         # 64 -> 8\n",
        "        self.fc   = nn.Linear(32 * feat_len, output_dim)  # 32*8 = 256\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.shape[0]\n",
        "        # reshape to (B, 64, 256) then permute to (B, 256, 64) for Conv1d\n",
        "        #print(f\"[TaskSpecificHead_CNN1D] Input x shape: {x.shape}\")\n",
        "        x = x.view(B, self.n_patches, self.feat_dim).permute(0, 2, 1).contiguous()\n",
        "        #print(f\"[TaskSpecificHead_CNN1D] Reshaped x shape: {x.shape}\")\n",
        "        x = self.pool(self.act(self.conv1(x)))  # (B,128,32)\n",
        "        x = self.drop(x)\n",
        "        x = self.pool(self.act(self.conv2(x)))  # (B, 64,16)\n",
        "        x = self.drop(x)\n",
        "        x = self.pool(self.act(self.conv3(x)))  # (B, 32, 8)\n",
        "        x = x.flatten(1)                        # (B, 32*8 = 256)\n",
        "        x = self.drop(x)\n",
        "        return self.fc(x)                       # (B, output_dim)\n",
        "    \n",
        "# Instantiate the model - 1\n",
        "output_dim = params.shape[1]  # number of parameters to predict\n",
        "head = TaskSpecificHead_CNN1D(n_patches = N_patches, feat_dim = dim, output_dim = output_dim).to(device)\n",
        "print(\"Num params encoder (in K): \", sum(p.numel()//10**3 for p in head.parameters()))\n",
        "print('Model architecture', head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%% Fine-tuning setup\n",
        "from types import SimpleNamespace\n",
        "from src.utils.select_fine_tuning_parameters import SelectFineTuningParameters\n",
        "\n",
        "# defining arguments (similar to ft code)\n",
        "def make_args(l1=False, l2=False, l3=False, l4=False, lr4=1e-4, wd4=0.0):\n",
        "    return SimpleNamespace(\n",
        "        ft_level1=l1, ft_level2=l2, ft_level3=l3, ft_level4=l4,\n",
        "        lr_level4=lr4, wd_level4=wd4\n",
        "    )\n",
        "\n",
        "# Level-1 only\n",
        "args = make_args(l1=True, l2=True)\n",
        "selector = SelectFineTuningParameters(morph, args)\n",
        "optimizer_1 = selector.configure_levels()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimizer for head network\n",
        "import torch.optim as optim\n",
        "optimizer_2 = optim.Adam(head.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss function\n",
        "loss_fn = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train/Finetune MORPH + TSH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trainer class\n",
        "class Trainer:\n",
        "    @staticmethod\n",
        "    def train_epoch(dataloader_train, model_1, model_2, optimizer_1, optimizer_2, device):\n",
        "        model_1.train() \n",
        "        model_2.train()\n",
        "        train_loss_1 = []\n",
        "        train_loss_2 = []\n",
        "        for step, batch in enumerate(dataloader_train):\n",
        "            x_tr, y_tr = batch\n",
        "            x_tr, y_tr = x_tr.to(device), y_tr.to(device)\n",
        "            #print(f'X: {x_tr.shape}, y: {y_tr.shape}')\n",
        "            optimizer_1.zero_grad()\n",
        "            optimizer_2.zero_grad()\n",
        "\n",
        "            # Model 1 forward + loss\n",
        "            _, z, x_nsp = model_1(x_tr)\n",
        "            #print(f\"[Trainer] Model 1 output shape: {x_nsp.shape}\")\n",
        "            #print(f\"[Trainer] Model 1 latent shape: {z.shape}\")\n",
        "            loss_1 = loss_fn(x_nsp.unsqueeze(1), x_tr) # autoencoder loss\n",
        "\n",
        "            # Model 1 backward\n",
        "            loss_1.backward()\n",
        "            optimizer_1.step()\n",
        "            train_loss_1.append(loss_1.item())\n",
        "\n",
        "            # Model 2 forward + backward\n",
        "            z = z.detach() # detach the two graphs\n",
        "            y_hat = model_2(z.squeeze(1))\n",
        "            #print(f\"[Trainer] Model 2 output shape: {y_hat.shape}\")\n",
        "            loss_2 = loss_fn(y_hat, y_tr)\n",
        "            loss_2.backward()\n",
        "            optimizer_2.step()\n",
        "            train_loss_2.append(loss_2.item())\n",
        "\n",
        "        return np.mean(train_loss_1), np.mean(train_loss_2)\n",
        "\n",
        "    @staticmethod\n",
        "    def test_epoch(dataloader_val, model_1, model_2, device):\n",
        "        model_1.eval() # Set the eval mode for model\n",
        "        model_2.eval()\n",
        "        test_loss_1 = []\n",
        "        test_loss_2 = []\n",
        "        with torch.no_grad(): # No need to track the gradients\n",
        "            for step, batch in enumerate(dataloader_val):\n",
        "                x_val, y_val = batch\n",
        "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
        "\n",
        "                # Model 1 forward\n",
        "                _, z, x_nsp = model_1(x_val)\n",
        "                loss_1 = loss_fn(x_nsp.unsqueeze(1), x_val)\n",
        "                test_loss_1.append(loss_1.item())\n",
        "                \n",
        "                # Model 2 forward\n",
        "                y_hat_2 = model_2(z.squeeze(1))\n",
        "                loss_2 = loss_fn(y_hat_2, y_val)\n",
        "                test_loss_2.append(loss_2.item())\n",
        "\n",
        "        return np.mean(test_loss_1), np.mean(test_loss_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "diz_loss = {'train_loss_morph':[],'train_loss_head':[], 'val_loss_morph':[], 'val_loss_head':[]}\n",
        "begin_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "   train_loss_morph, train_loss_head = Trainer.train_epoch(dataloader_train, morph, head, \n",
        "                                                           optimizer_1, optimizer_2, device)\n",
        "   val_loss_morph, val_loss_head = Trainer.test_epoch(dataloader_val, morph, head, device)\n",
        "\n",
        "   print(\n",
        "    f\"\\n EPOCH {epoch+1}/{num_epochs} TIME: {time.time()-begin_time:.2f}s, \"\n",
        "    f\"train loss morph {train_loss_morph:.4f}, \"\n",
        "    f\"val loss morph {val_loss_morph:.4f}, \"\n",
        "    f\"train loss head {train_loss_head:.4f}, \"\n",
        "    f\"val loss head {val_loss_head:.4f}\"\n",
        ")\n",
        "\n",
        "   # store the losses per epoch\n",
        "   diz_loss['train_loss_morph'].append(train_loss_morph)\n",
        "   diz_loss['train_loss_head'].append(train_loss_head)\n",
        "   diz_loss['val_loss_morph'].append(val_loss_morph)\n",
        "   diz_loss['val_loss_head'].append(val_loss_head)\n",
        "\n",
        "# Save the model\n",
        "torch.save(morph.state_dict(), os.path.join(model_dir, 'morph_ft_icf.pth'))\n",
        "torch.save(head.state_dict(), os.path.join(model_dir, 'head_ft_icf.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Plot train vs val loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print train and val loss\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(diz_loss['train_loss_morph'], '-ok', label='Train',)\n",
        "plt.plot(diz_loss['val_loss_morph'], '-^r', label='Valid')\n",
        "plt.xlabel('Epoch',fontsize=20)\n",
        "plt.ylabel('Average Loss (MORPH)',fontsize=20)\n",
        "plt.legend([\"tr_total\", \"val_total\"])\n",
        "plt.title('Training & Validation loss', fontsize = 20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.show()\n",
        "plt.savefig(os.path.join(results_dir, 'loss_ft_morph_icf.png'))\n",
        "\n",
        "\n",
        "# print train and val loss\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(diz_loss['train_loss_head'], '-ok', label='Train',)\n",
        "plt.plot(diz_loss['val_loss_head'], '-^r', label='Valid')\n",
        "plt.xlabel('Epoch',fontsize=20)\n",
        "plt.ylabel('Average Loss (HEAD)',fontsize=20)\n",
        "plt.legend([\"tr_total\", \"val_total\"])\n",
        "plt.title('Training & Validation loss', fontsize = 20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.show()\n",
        "plt.savefig(os.path.join(results_dir, 'loss_ft_head_icf.png'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing MORPH + TSH on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing\n",
        "def testing(dataloader_test, model_1, model_2, device):\n",
        "        model_1.eval() # Set the eval mode for model\n",
        "        model_2.eval()\n",
        "        mse_loss_1, mse_loss_2 = [], []\n",
        "        x_org, x_pred, y_org, y_pred = [], [], [], []\n",
        "        with torch.no_grad(): # No need to track the gradients\n",
        "            for _, batch in enumerate(dataloader_test):\n",
        "                x_test, y_test = batch\n",
        "                x_test, y_test = x_test.to(device), y_test.to(device)\n",
        "\n",
        "                # Model 1 forward\n",
        "                _, z, x_nsp = model_1(x_test)\n",
        "                loss_1 = loss_fn(x_nsp.unsqueeze(1), x_test)\n",
        "                mse_loss_1.append(loss_1.item())\n",
        "                \n",
        "                # Model 2 forward\n",
        "                y_hat_2 = model_2(z.squeeze(1))\n",
        "                loss_2 = loss_fn(y_hat_2, y_test)\n",
        "                mse_loss_2.append(loss_2.item())\n",
        "\n",
        "                # Collect original and predicted samples\n",
        "                x_org.append(x_test.cpu().numpy())\n",
        "                x_pred.append(x_nsp.unsqueeze(1).cpu().numpy())\n",
        "                y_org.append(y_test.cpu().numpy())\n",
        "                y_pred.append(y_hat_2.cpu().numpy())\n",
        "\n",
        "        return mse_loss_1, mse_loss_2, x_org, x_pred, y_org, y_pred\n",
        "\n",
        "# get the test losses and predictions\n",
        "mse_loss_main, mse_loss_head, x_org, x_pred, y_org, y_pred = testing(dataloader_test, morph, head, device)\n",
        "print(f\"Test Loss - Morph: {np.mean(mse_loss_main):.4f}, Head: {np.mean(mse_loss_head):.4f}\")\n",
        "print(f'x_org shape: {x_org[0].shape}, x_pred shape: {x_pred[0].shape}')\n",
        "print(f'y_org shape: {y_org[0].shape}, y_pred shape: {y_pred[0].shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot y_org vs y_pred\n",
        "def plot_ytrue_vs_ypred(y_org, y_pred):\n",
        "    y_org_arr = np.concatenate(y_org, axis=0)\n",
        "    y_pred_arr =  np.concatenate(y_pred, axis=0)\n",
        "    print(f'y_org shape: {y_org_arr.shape}, y_pred shape: {y_pred_arr.shape}')\n",
        "    plt.figure(figsize=(32, 4))\n",
        "    for c in range(y_org_arr.shape[1]):\n",
        "        r2 = np.corrcoef(y_org_arr[:, c], y_pred_arr[:, c])[0, 1] ** 2\n",
        "        mse = np.mean((y_org_arr[:, c] - y_pred_arr[:, c])**2)\n",
        "        print(f'Parameter {c+1}: R^2 = {r2:.4f}, MSE = {mse:.4f}')\n",
        "        plt.subplot(1, 5, c+1)\n",
        "        plt.plot(y_org_arr[:, c], y_pred_arr[:, c], 'o', label='Original vs Predicted')\n",
        "        plt.title(f'Parameter {c+1}, r2 = {r2:.4f}, MSE = {mse:.4f}')\n",
        "        plt.xlabel('True')\n",
        "        plt.ylabel('Predicted')\n",
        "        plt.legend()\n",
        "    plt.show()\n",
        "    plt.savefig(os.path.join(HERE, 'ytrue_vs_ypred.png'), dpi=300)\n",
        "\n",
        "# plot for all parameters\n",
        "plot_ytrue_vs_ypred(y_org, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plots of x_org vs x_pred\n",
        "def plot_original_vs_predicted(x_org, x_pred):\n",
        "    len_samples = len(x_org)\n",
        "    print(f'Number of test samples: {len_samples}, each of shape: {x_org[0].shape}')\n",
        "    select_samples = np.random.choice(len_samples, 5, replace=False)\n",
        "    print(f'Selected samples: {select_samples}')\n",
        "\n",
        "    for idx in select_samples:\n",
        "        x_o = x_org[idx][:,0,:,:,0,:,:]       # (1, 2, 2, 1, 64, 64) -> (2, 2, 64, 64)\n",
        "        x_p = x_pred[idx][:,0,:,:,0,:,:]      # (1, 2, 2, 1, 64, 64) -> (2, 2, 64, 64)\n",
        "        x_o = x_o.reshape(-1, 4, 64, 64)      # (B, 4, 64, 64)\n",
        "        x_p = x_p.reshape(-1, 4, 64, 64)      # (B, 4, 64, 64)\n",
        "        print(f'x_org shape: {x_o.shape}, x_pred shape: {x_p.shape}')\n",
        "        \n",
        "        idx = np.random.randint(0, x_o.shape[0])  # pick a random sample from the batch\n",
        "        x_o = x_o[idx]  # (4, 64, 64)\n",
        "        x_p = x_p[idx]  # (4, 64, 64)\n",
        "\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "        for c in range(4):\n",
        "            axes[0, c].imshow(x_o[c, :, :], cmap='plasma', origin='lower')\n",
        "            axes[0, c].set_title(f'Original - Channel {c}')\n",
        "            axes[0, c].axis('off')\n",
        "\n",
        "            axes[1, c].imshow(x_p[c, :, :], cmap='plasma', origin='lower')\n",
        "            axes[1, c].set_title(f'Predicted - Channel {c}')\n",
        "            axes[1, c].axis('off')\n",
        "        plt.suptitle(f'Sample {idx}: Original vs Predicted')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        plt.savefig(os.path.join(HERE, f'original_vs_predicted_sample_{idx}.png'), dpi=300)\n",
        "\n",
        "plot_original_vs_predicted(x_org, x_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Standalone Model on ICF data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Standalone surrogate (SS): CNN2D encoder for regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standalone model\n",
        "import torch.nn as nn\n",
        "\n",
        "class Standalone_CNN2D(nn.Module):\n",
        "    def __init__(self, output_dim=5):\n",
        "        super(Standalone_CNN2D, self).__init__()\n",
        "        # 64x64 input with 4 channels\n",
        "        self.conv1 = nn.Conv2d(in_channels=4, out_channels=32, kernel_size=3, stride=1, padding=1)   # -> 32 x 64 x 64\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)  # -> 64 x 32 x 32\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1) # -> 128 x 16 x 16\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1) # -> 256 x 8 x 8\n",
        "\n",
        "        self.activation = nn.GELU()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # After three 2x2 pools: 64 -> 32 -> 16 -> 8\n",
        "        # So features = 256 * 8 * 8 = 16384\n",
        "        self.fc1 = nn.Linear(256 * 8 * 8, 256)\n",
        "        self.fc2 = nn.Linear(256, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.conv1(x))  # 32 x 64 x 64\n",
        "        x = self.activation(self.conv2(x))  # 64 x 32 x 32\n",
        "        x = self.activation(self.conv3(x))  # 128 x 16 x 16\n",
        "        x = self.activation(self.conv4(x))  # 256 x 8 x 8\n",
        "        x = self.flatten(x)                  # flatten\n",
        "        x = self.activation(self.fc1(x))    # 256\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)                              # logits of shape (B, output_dim)\n",
        "\n",
        "# Instantiate the model - 2\n",
        "output_dim = params.shape[1]  # number of parameters to predict\n",
        "model_ss = Standalone_CNN2D(output_dim).to(device)\n",
        "print(\"Num params encoder (in M): \", sum(p.numel()//10**6 for p in model_ss.parameters()))\n",
        "print('Model architecture', model_ss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Training SS (CNN2D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trainer class\n",
        "class Trainer2:\n",
        "    @staticmethod\n",
        "    def train_epoch_ss(dataloader_train, model, optimizer, device):\n",
        "        model.train() \n",
        "        train_loss = []\n",
        "        for step, batch in enumerate(dataloader_train):\n",
        "            x_tr, y_tr = batch\n",
        "            x_tr, y_tr = x_tr.to(device), y_tr.to(device)\n",
        "            # print(f'X: {x_tr.shape}, y: {y_tr.shape}')\n",
        "            # reshape x_tr\n",
        "            x_tr = x_tr[:, 0, :, :, 0, :, :].reshape(-1, 4, 64, 64)  # (B,T,F,C,D,H,W) -> (B, 4, 64, 64)\n",
        "            # print(f'X: {x_tr.shape}, y: {y_tr.shape}')\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Model 1 forward + loss\n",
        "            y_hat = model(x_tr)\n",
        "            loss = loss_fn(y_hat, y_tr) \n",
        "\n",
        "            # Model 1 backward\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        return np.mean(train_loss)\n",
        "\n",
        "    @staticmethod\n",
        "    def test_epoch_ss(dataloader_val, model, device):\n",
        "        model.eval() # Set the eval mode for model\n",
        "        test_loss = []\n",
        "        with torch.no_grad(): # No need to track the gradients\n",
        "            for step, batch in enumerate(dataloader_val):\n",
        "                x_val, y_val = batch\n",
        "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
        "\n",
        "                # print(f'X: {x_tr.shape}, y: {y_tr.shape}')\n",
        "                # reshape x_tr\n",
        "                x_val = x_val[:, 0, :, :, 0, :, :].reshape(-1, 4, 64, 64)  # (B,T,F,C,D,H,W) -> (B, 4, 64, 64)\n",
        "                # print(f'X: {x_val.shape}, y: {y_val.shape}')\n",
        "\n",
        "                # Modelforward\n",
        "                y_hat = model(x_val)\n",
        "                loss = loss_fn(y_hat, y_val)\n",
        "                test_loss.append(loss.item())\n",
        "\n",
        "        return np.mean(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "diz_loss_ss = {'train_loss':[], 'val_loss':[]}\n",
        "begin_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "   train_loss = Trainer2.train_epoch_ss(dataloader_train, model_ss, optimizer_2, device)\n",
        "   val_loss = Trainer2.test_epoch_ss(dataloader_val, model_ss, device)\n",
        "\n",
        "   print(\n",
        "    f\"\\n EPOCH {epoch+1}/{num_epochs} TIME: {time.time()-begin_time:.2f}s, \"\n",
        "    f\"train loss {train_loss:.4f}, \"\n",
        "    f\"val loss {val_loss:.4f}\"\n",
        ")\n",
        "\n",
        "   # store the losses per epoch\n",
        "   diz_loss_ss['train_loss'].append(train_loss)\n",
        "   diz_loss_ss['val_loss'].append(val_loss)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model_ss.state_dict(), os.path.join(model_dir, 'model_ss_icf.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### plot training and val loss for SS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print train and val loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(diz_loss_ss['train_loss'], '-ok', label='Train',)\n",
        "plt.plot(diz_loss_ss['val_loss'], '-^r', label='Valid')\n",
        "plt.xlabel('Epoch',fontsize=20)\n",
        "plt.ylabel('Average Loss',fontsize=20)\n",
        "plt.legend([\"tr_total\", \"val_total\"])\n",
        "plt.title('Training & Validation loss (Standalone model)', fontsize = 20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.show()\n",
        "plt.savefig(os.path.join(results_dir, 'loss_ss_icf.png'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing SS on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing\n",
        "def testing_ss(dataloader_test, model, device):\n",
        "        model.eval() # Set the eval mode for model\n",
        "        test_loss = []\n",
        "        y_org, y_pred = [], []\n",
        "        with torch.no_grad(): # No need to track the gradients\n",
        "            for _, batch in enumerate(dataloader_test):\n",
        "                x_test, y_test = batch\n",
        "                x_test, y_test = x_test.to(device), y_test.to(device)\n",
        "\n",
        "                # print(f'X: {x_tr.shape}, y: {y_tr.shape}')\n",
        "                # reshape x_tr\n",
        "                x_test = x_test[:, 0, :, :, 0, :, :].reshape(-1, 4, 64, 64)  # (B,T,F,C,D,H,W) -> (B, 4, 64, 64)\n",
        "                # print(f'X: {x_test.shape}, y: {y_test.shape}')\n",
        "\n",
        "                # Model forward\n",
        "                y_hat = model(x_test)\n",
        "                loss = loss_fn(y_hat, y_test)\n",
        "                test_loss.append(loss.item())\n",
        "\n",
        "                # Collect original and predicted samples\n",
        "                y_org.append(y_test.cpu().numpy())\n",
        "                y_pred.append(y_hat.cpu().numpy())\n",
        "\n",
        "        return test_loss, y_org, y_pred\n",
        "\n",
        "# get the test losses and predictions\n",
        "test_losses_ss, y_org_ss, y_pred_ss = testing_ss(dataloader_test, model_ss, device)\n",
        "print(f'y_org shape: {y_org_ss[0].shape}, y_pred shape: {y_pred_ss[0].shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot for all parameters\n",
        "plot_ytrue_vs_ypred(y_org_ss, y_pred_ss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
